{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估指標與其用途\n",
    "\n",
    "在機器學習模型做出預測之後，用以衡量預測優劣的指標被稱為<b>評估指標</b>。機器學習分類任務的評估指標有<b>分類精度</b>和迴歸問題的<b>均方根誤差</b>..等等，評估指標可以提供明確客觀的依據，我們得以衡量機器學習流程的優劣，以下是幾個常見的情境:\n",
    "<li>以同樣資料來源但不同的縮放方法產生的資料，訓練同一個機器學習模型，使用評估指標能衡量用於此機器學習模型最好的一種縮放方法\n",
    "<li>以同樣資料、訓練多個機器學習模型，使用評估指標能衡量在使用此資料來源，使用哪一個機器學習模型的表現最佳\n",
    "<li>以同樣資料、訓練一種機器學習模型，但使用多組不同的參數，使用評估指標能衡量哪一組機器學習的參數最佳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標\n",
    "\n",
    "此筆記本中，將以Python實現四個標準預測\n",
    "<li>如何實現分類準確性。\n",
    "<li>如何實現和解釋混淆矩陣。\n",
    "<li>如何實現回歸的平均絕對誤差。\n",
    "<li>如何實現回歸的均方根誤差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [分類]分類準確性-Classification Accuracy\n",
    "最直觀的機器學習分類任務的評估指標，是計算其所有預測當中成功預測的百分比。分類準確性的結果是0-1之間的數字，0代表完全沒有成功的預測；1代表預測全部成功。分類準確性需要有正確的label以及機器學習預測的label來做評估。以下為公式:\n",
    "\n",
    "\\begin{align}\n",
    "accuracy = \\frac{correct prediction}{total prediction}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    分類準確性，計算所有預測中被正確預測的比例\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    一個介於0-1之間的數字，代表被正確預測的標籤的比例  \n",
    "    \"\"\"\n",
    "    correct = 0    \n",
    "    for i in range(len(actual_labels)):\n",
    "        if predicted_labels[i] == actual_labels[i]:\n",
    "            correct += 1\n",
    "    return correct / len(actual_labels)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#實際的標籤\n",
    "actual_labels = [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "#機器學習預測的標籤\n",
    "predicted_labels = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "#計算機器學習分類預測的準確度\n",
    "accuracy_metric(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分類準確性之缺點\n",
    "分類準確性是很直觀的評估指標，我們得以知道預測命中的百分比。但是當遇到一些情形，分類準確性會失去其意義或表現得近乎假象。假設我們使用的機器學習模型是建立在二元分類的任務上(預測<b>是</b>或<b>否</b>)，但表現極差，對所有的分類預測都只預測為0。但是當遇到這樣的資料集；有高達90%的資料label為0，僅有10%為1，即使我們的機器學習模型只會預測全部標籤皆為0，但我們的分類準確性還是高達90%的準確率，讓我們誤以為機器學習模型的表現沒有問題。也因此當遇到分佈不平衡的資料集時(某一些類別多於其他類別)，時常分類準確性會誤導我們對機器學習模型表現的認知。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. [分類]混淆矩陣-Confushion matrix\n",
    "評估機器學習模型的分類性能的更好方法是使用混淆矩陣。混淆矩陣的概念是用來計算某類別被錯誤預測為其他類的次數。混淆矩陣是二維矩陣且寬等於高，也就是說假設資料總共有N個類別，則用來評估該資料之預測結果的混淆矩陣維度為NxN。一個簡單的理解方式是將混淆矩陣看成一個table，每一行(row)，代表實際類別n，而該行的每一個欄位(column)該實際類別被預測為某類別的次數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confushion_matrix(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    混淆矩陣，計算所有被正確預測以及被錯誤預測為其他類別的次數總計\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    unique:一個所有類別的列表\n",
    "    matrix:一個混淆矩陣  \n",
    "    \"\"\"\n",
    "    \n",
    "    unique = set(actual_labels)#所有類別的列表\n",
    "    \n",
    "    matrix = [list() for x in range(len(unique))] \n",
    "    for i in range(len(unique)):\n",
    "        matrix[i] = [0 for j in range(len(unique))]\n",
    "        \n",
    "    lookup = {}\n",
    "    \n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "        \n",
    "    for i in range(len(actual_labels)):\n",
    "        x = lookup[actual_labels[i]]\n",
    "        y = lookup[predicted_labels[i]]\n",
    "        matrix[x][y] += 1\n",
    "        \n",
    "    return unique, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 0], [2, 1]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#實際的標籤\n",
    "actual_labels =    [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "#機器學習預測的標籤\n",
    "predicted_labels = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "#計算混淆矩陣\n",
    "#實際上是0但是被預測為1的次數是0，實際標籤與預測標籤同為0的次數為9次。\n",
    "#實際上是1但是被預測為0的次數為2，實際標籤與預測標籤同為1的次數為1次。\n",
    "lookup, matrix = confushion_matrix(actual_labels,\n",
    "                                   predicted_labels)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A)0 1\n",
      "(P)---\n",
      "0| 9 0\n",
      "1| 2 1\n"
     ]
    }
   ],
   "source": [
    "#視覺化混淆矩陣\n",
    "def print_confusion_matrix(unique, matrix):\n",
    "    print('(A)' + ' '.join(str(x) for x in unique))\n",
    "    print('(P)---')\n",
    "    for i, x in enumerate(unique):\n",
    "        print(\"%s| %s\" % (x, ' '.join(str(x) for x in matrix[i])))\n",
    "\n",
    "print_confusion_matrix(lookup, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 0],\n",
       "       [2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 混淆矩陣的視覺化\n",
    "混淆矩陣視覺化相較於觀看數字來得直觀許多，以下演示用機器學習模型做分類預測，並用熱度圖作為混淆矩陣視覺化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#讀取鳶尾花資料集\n",
    "iris_data = load_iris()\n",
    "iris_length = iris_data['data']\n",
    "iris_labels = iris_data['target']\n",
    "#切割成訓練集以及測試集\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris_length, iris_labels, test_size=0.5)\n",
    "\n",
    "#訓練資料一覽\n",
    "(train_x[:10])\n",
    "#標籤資料一覽\n",
    "print(train_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "y_pred = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(confusion_matrix(test_y, y_pred))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 [分類]精密度-precision\n",
    "混淆矩陣為您提供了大量信息，但有時我們傾向更更簡潔且有直接敘述性的指標，我們可以使用稱為分類器的精密度(precision)作為指標。<br/>\n",
    "公式:\n",
    "\\begin{align}\n",
    "precision = \\frac{TP}{TP + FP}\n",
    "\\end{align}\n",
    "\n",
    "以數值為0或1的二元分類為例，TP是true positive的縮寫，意思是被正確預測的正面(1)實例，而FP是false positive的縮寫，代表被錯誤預測為正面(1)實例的反面(0)實例。公式的含意是所有被分類為正面實例中實際被正確分類的比例。也就是被預測為1的資料當中，真正是1的的比例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_metric(actual_labels, predicted_labels):\n",
    "    tp = 0\n",
    "    tp_plus_fp = 0\n",
    "    \n",
    "    for i in range(len(actual_labels)):\n",
    "        if predicted_labels[i] == 1:\n",
    "            if actual_labels[i] == 1:\n",
    "                tp += 1\n",
    "            tp_plus_fp += 1\n",
    "    \n",
    "    return tp / tp_plus_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#實際的標籤\n",
    "actual_labels =       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "#機器學習預測的標籤\n",
    "predicted_labels =    [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "precision_metric(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(actual_labels, predicted_labels) # == 4344 / (4344 + 1307)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 [分類]召回率-recall\n",
    "精密度指標通常與被稱為召回率的指標一起使用，召回率指標的公式如下:\n",
    "\n",
    "公式:\n",
    "\\begin{align}\n",
    "recall = \\frac{TP}{TP + FN}\n",
    "\\end{align}\n",
    "\n",
    "精密度指標代表著被預測為正面的實例當中正確的比例，但是在精密度指標我們只知道被預測為正面實例的正確率，卻少了實際為正面實例卻沒有被預測出來的觀點。召回率指標彌補了這個盲區，代表實際為正面實例當中有多少實例被正確預測、或說被模型認出來了。<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_metric(actual_labels, predicted_labels):\n",
    "    tp = 0\n",
    "    tp_plus_fn = 0\n",
    "    \n",
    "    for i in range(len(actual_labels)):\n",
    "        if predicted_labels[i] == 1 and actual_labels[i] == 1:\n",
    "            tp += 1\n",
    "            tp_plus_fn += 1\n",
    "        elif predicted_labels[i] == 0 and actual_labels[i] == 1:\n",
    "            tp_plus_fn += 1\n",
    "\n",
    "        \n",
    "    return tp / tp_plus_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#實際的標籤\n",
    "actual_labels =       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "#機器學習預測的標籤\n",
    "predicted_labels =    [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "\n",
    "#召回率指標\n",
    "recall_metric(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(actual_labels, predicted_labels) # == 4344 / (4344 + 1307)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. [迴歸]平均絕對誤差-Mean Absolute Error (MAE)\n",
    "平均絕對誤差測量一組預測中的誤差的平均幅度，而不考慮它們的正負。是測試樣本中預測和實際觀察之間絕對差異的平均值。公式如下:\n",
    "\\begin{align}\n",
    "MAE = \\frac{1}{n}\\times\\frac{\\sum_{i=1}^n|y_i - \\hat{y_i}|}{n - 1}\n",
    "\\end{align}\n",
    "另外如果MAE未採用絕對值（未消除誤差的符號），則平均誤差變為平均偏差誤差（MBE），並且通常用於測量平均模型偏差。 MBE可以傳達有用的信息，但應該謹慎解釋，因為正面和負面的錯誤都會被取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_metric(actual_values, predicted_values):\n",
    "    abs_error = 0\n",
    "    for i in range(len(actual_values)):\n",
    "        abs_error += abs(actual_values[i] - predicted_values[i])\n",
    "    return abs_error / len(actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007999999999999993"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test RMSE\n",
    "actual = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "predicted = [0.11, 0.19, 0.29, 0.41, 0.5]\n",
    "mae = mae_metric(actual, predicted)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. [迴歸]均方根誤差-Root-Mean-Square Error (RMSE)\n",
    "RMSE測量誤差的平均幅度。 它是預測和實際觀察之間平均差異平均值的平方根。公式如下:\n",
    "\\begin{align}\n",
    "RMSE = \\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}{\\Big(\\frac{y_i - \\hat{y_i}}{\\sigma_i}\\Big)^2}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def rmse_metric(actual_values, predicted_values):\n",
    "    \"\"\"\n",
    "    均方根誤差，計算預測和實際觀察之間平均差異平均值的平方根\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    rmse:均方根誤差\n",
    "    \"\"\"\n",
    "    diff_sum = 0\n",
    "    for i in range(len(actual_values)):\n",
    "        diff_sum += (actual_values[i] - predicted_values[i])**2\n",
    "        \n",
    "    return sqrt(diff_sum / len(actual_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00894427190999915"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "predicted = [0.11, 0.19, 0.29, 0.41, 0.5]\n",
    "rmse_metric(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numpy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rmse_metric(actual_values, predicted_values):\n",
    "    \"\"\"\n",
    "    均方根誤差，計算預測和實際觀察之間平均差異平均值的平方根\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    rmse:均方根誤差\n",
    "    \"\"\"\n",
    "    mse = np.mean((np.array(actual_values) - np.array(predicted_values))**2)\n",
    "        \n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00894427190999915"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "predicted = [0.11, 0.19, 0.29, 0.41, 0.5]\n",
    "rmse_metric(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE 與 RMSE之比較\n",
    "相似之處：MAE和RMSE都變量為單位表示平均模型預測誤差。 兩個度量都可以在0到∞的範圍內，並且正負無關緊要。 它們是負面導向的分數，這意味著較低的值更好。\n",
    "\n",
    "差異：取平均誤差的平方根對RMSE有一些有趣的影響。 由於誤差在平均之前是平方的，因此RMSE對大誤差給出相對較高的權重。 這意味著當特別不希望出現大錯誤時RMSE更有用。 下面的Case1-3顯示了MAE穩定且RMSE增加的示例，因為與誤差幅度的頻率分佈和方差的幅度差異。\n",
    "\n",
    "RMSE不一定隨著誤差的變化而增加，RMSE隨方差的誤差幅度和頻率分佈而增加。\n",
    "為了演示，請考慮下表中的案例4和案例5。 案例4具有相同數量的0和5的測試錯誤，案例5具有相同數量的3和4的測試錯誤。案例4中的錯誤差異更大但案例4和案例5的RMSE相同。也就是說當方差的頻率分佈較為集中時，RMSE的數值近於MAE，但是隨著頻率分佈較離散時會高於MAE。另外即使頻率分佈趨於集中，但是有極端值產生時，RMSE還是會大幅增加。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://ithelp.ithome.com.tw/upload/images/20181214/20111826istVtav0RA.jpg' style='width:1000px;float:left;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://ithelp.ithome.com.tw/upload/images/20181214/20111826tQ1ShERAlP.jpg' style='width:1000px;float:left;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE 與 RMSE之比較:結論\n",
    "RMSE具有更多懲罰大誤差值的好處，因此在某些情況下可能更合適，例如，當我們希望誤差的幅度與頻率散布盡可能的小時我們會使用RMSE，但如果誤差的幅度大小在我們看來並不在意(不管誤差10或是誤差100都是一樣差)那麼MAE更合適。從解釋性的角度來看，MAE顯然更讓人容易理解。 RMSE不僅僅描述平均誤差，而且還有其他更難以梳理的含義。另一方面，RMSE相對於MAE的一個明顯優勢是RMSE避免使用絕對值，這在許多數學計算中是不可取的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More to come.....\n",
    "評估指標多種多樣，未來將補充更多重要的指標，例如:\n",
    "<li>f1-score\n",
    "<li>AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
