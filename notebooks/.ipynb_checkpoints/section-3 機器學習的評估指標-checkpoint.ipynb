{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估指標與其用途\n",
    "\n",
    "在機器學習模型做出預測之後，用以衡量預測優劣的指標被稱為<b>評估指標</b>。機器學習分類任務的評估指標有<b>分類精度</b>和迴歸問題的<b>均方根誤差</b>..等等，評估指標可以提供明確客觀的依據，我們得以衡量機器學習流程的優劣，以下是幾個常見的情境:\n",
    "<li>以同樣資料來源但不同的縮放方法產生的資料，訓練同一個機器學習模型，使用評估指標能衡量用於此機器學習模型最好的一種縮放方法\n",
    "<li>以同樣資料、訓練多個機器學習模型，使用評估指標能衡量在使用此資料來源，使用哪一個機器學習模型的表現最佳\n",
    "<li>以同樣資料、訓練一種機器學習模型，但使用多組不同的參數，使用評估指標能衡量哪一組機器學習的參數最佳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標\n",
    "\n",
    "此筆記本中，將以Python實現四個標準預測\n",
    "<li>如何實現分類準確性。\n",
    "<li>如何實現和解釋混淆矩陣。\n",
    "<li>如何實現回歸的平均絕對誤差。\n",
    "<li>如何實現回歸的均方根誤差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [分類]分類準確性-Classification Accuracy\n",
    "最直觀的機器學習分類任務的評估指標，是計算其所有預測當中成功預測的百分比。分類準確性的結果是0-1之間的數字，0代表完全沒有成功的預測；1代表預測全部成功。分類準確性需要有正確的label以及機器學習預測的label來做評估。以下為公式:\n",
    "\n",
    "\\begin{align}\n",
    "accuracy = \\frac{correct prediction}{total prediction}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    分類準確性，計算所有預測中被正確預測的比例\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    一個介於0-1之間的數字，代表被正確預測的標籤的比例  \n",
    "    \"\"\"\n",
    "    correct = 0    \n",
    "    for i in range(len(actual_labels)):\n",
    "        if predicted_labels[i] == actual_labels[i]:\n",
    "            correct += 1\n",
    "    return correct / len(actual_labels)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#實際的標籤\n",
    "actual_labels = [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "#機器學習預測的標籤\n",
    "predicted_labels = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "#計算機器學習分類預測的準確度\n",
    "accuracy_metric(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分類準確性之缺點\n",
    "分類準確性是很直觀的評估指標，我們得以知道預測命中的百分比。但是當遇到一些情形，分類準確性會失去其意義或表現得近乎假象。假設我們使用的機器學習模型是建立在二元分類的任務上(預測<b>是</b>或<b>否</b>)，但表現極差，對所有的分類預測都只預測為0。但是當遇到這樣的資料集；有高達90%的資料label為0，僅有10%為1，即使我們的機器學習模型只會預測全部標籤皆為0，但我們的分類準確性還是高達90%的準確率，讓我們誤以為機器學習模型的表現沒有問題。也因此當遇到分佈不平衡的資料集時(某一些類別多於其他類別)，時常分類準確性會誤導我們對機器學習模型表現的認知。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. [分類]混淆矩陣-Confushion matrix\n",
    "評估機器學習模型的分類性能的更好方法是使用混淆矩陣。混淆矩陣的概念是用來計算某類別被錯誤預測為其他類的次數。混淆矩陣是二維矩陣且寬等於高，也就是說假設資料總共有N個類別，則用來評估該資料之預測結果的混淆矩陣維度為NxN。一個簡單的理解方式是將混淆矩陣看成一個table，每一行(row)，代表實際類別n，而該行的每一個欄位(column)該實際類別被預測為某類別的次數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confushion_matrix(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    混淆矩陣，計算所有被正確預測以及被錯誤預測為其他類別的次數總計\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    unique:一個所有類別的列表\n",
    "    matrix:一個混淆矩陣  \n",
    "    \"\"\"\n",
    "    \n",
    "    unique = set(actual_labels)#所有類別的列表\n",
    "    \n",
    "    matrix = [list() for x in range(len(unique))] \n",
    "    for i in range(len(unique)):\n",
    "        matrix[i] = [0 for j in range(len(unique))]\n",
    "        \n",
    "    lookup = {}\n",
    "    \n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "        \n",
    "    for i in range(len(actual_labels)):\n",
    "        x = lookup[actual_labels[i]]\n",
    "        y = lookup[predicted_labels[i]]\n",
    "        matrix[x][y] += 1\n",
    "        \n",
    "    return unique, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 0], [2, 1]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#實際的標籤\n",
    "actual_labels =    [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "#機器學習預測的標籤\n",
    "predicted_labels = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "#計算混淆矩陣\n",
    "#而實際上是0但是被預測為1的次數是0，實際標籤與預測標籤同為0的次數為9次。\n",
    "#實際上是1但是被預測為0的次數為2，實際標籤與預測標籤同為1的次數為1次。\n",
    "lookup, matrix = confushion_matrix(actual_labels,\n",
    "                                   predicted_labels)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A)0 1\n",
      "(P)---\n",
      "0| 9 0\n",
      "1| 2 1\n"
     ]
    }
   ],
   "source": [
    "#視覺化混淆矩陣\n",
    "def print_confusion_matrix(unique, matrix):\n",
    "    print('(A)' + ' '.join(str(x) for x in unique))\n",
    "    print('(P)---')\n",
    "    for i, x in enumerate(unique):\n",
    "        print(\"%s| %s\" % (x, ' '.join(str(x) for x in matrix[i])))\n",
    "\n",
    "print_confusion_matrix(lookup, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 0],\n",
       "       [2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. [迴歸]平均絕對誤差-Mean Absolute Error (MAE)\n",
    "平均絕對誤差測量一組預測中的誤差的平均幅度，而不考慮它們的正負。是測試樣本中預測和實際觀察之間絕對差異的平均值。公式如下:\n",
    "\\begin{align}\n",
    "MAE = \\frac{1}{n}*\\frac{\\sum_{i=1}^n|y_i - \\hat{y_i}|}{n - 1}\n",
    "\\end{align}\n",
    "另外如果MAE未採用絕對值（未消除誤差的符號），則平均誤差變為平均偏差誤差（MBE），並且通常用於測量平均模型偏差。 MBE可以傳達有用的信息，但應該謹慎解釋，因為正面和負面的錯誤都會被取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_metric(actual_values, predicted_values):\n",
    "    abs_error = 0\n",
    "    for i in range(len(actual_values)):\n",
    "        abs_error += abs(actual_values[i] - predicted_values[i])\n",
    "    return abs_error / len(actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007999999999999993"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test RMSE\n",
    "actual = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "predicted = [0.11, 0.19, 0.29, 0.41, 0.5]\n",
    "mae = mae_metric(actual, predicted)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. [迴歸]均方根誤差-Root-Mean-Square Error (RMSE)\n",
    "RMSE測量誤差的平均幅度。 它是預測和實際觀察之間平均差異平均值的平方根。公式如下:\n",
    "\\begin{align}\n",
    "RMSE = \\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}{\\Big(\\frac{y_i - \\hat{y_i}}{\\sigma_i}\\Big)^2}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def rmse_metric(actual_values, predicted_values):\n",
    "    \"\"\"\n",
    "    均方根誤差，計算預測和實際觀察之間平均差異平均值的平方根\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    rmse:均方根誤差\n",
    "    \"\"\"\n",
    "    diff_sum = 0\n",
    "    for i in range(len(actual_values)):\n",
    "        diff_sum += (actual_values[i] - predicted_values[i])**2\n",
    "        \n",
    "    return sqrt(diff_sum / len(actual_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00894427190999915"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "predicted = [0.11, 0.19, 0.29, 0.41, 0.5]\n",
    "rmse_metric(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numpy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rmse_metric(actual_values, predicted_values):\n",
    "    \"\"\"\n",
    "    均方根誤差，計算預測和實際觀察之間平均差異平均值的平方根\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    rmse:均方根誤差\n",
    "    \"\"\"\n",
    "    mse = np.mean((np.array(actual_values) - np.array(predicted_values))**2)\n",
    "        \n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00894427190999915"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "predicted = [0.11, 0.19, 0.29, 0.41, 0.5]\n",
    "rmse_metric(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE 與 RMSE之比較\n",
    "相似之處：MAE和RMSE都變量為單位表示平均模型預測誤差。 兩個度量都可以在0到∞的範圍內，並且正負無關緊要。 它們是負面導向的分數，這意味著較低的值更好。\n",
    "\n",
    "差異：取平均誤差的平方根對RMSE有一些有趣的影響。 由於誤差在平均之前是平方的，因此RMSE對大誤差給出相對較高的權重。 這意味著當特別不希望出現大錯誤時RMSE更有用。 下面的三個表格顯示了MAE穩定且RMSE增加的示例，因為與誤差幅度的頻率分佈和方差的幅度差異。\n",
    "<img src='images\\section-3\\rmse_mae_compare_1.jpg' style='width:700px;'>\n",
    "\n",
    "RMSE不一定隨著誤差的變化而增加，RMSE隨方差的誤差幅度和頻率分佈而增加。\n",
    "為了演示，請考慮下表中的案例4和案例5。 案例4具有相同數量的0和5的測試錯誤，案例5具有相同數量的3和4的測試錯誤。案例4中的錯誤差異更大但案例4和案例5的RMSE相同。也就是說當方差的頻率分佈較為集中時，RMSE的數值近於MAE，但是隨著頻率分佈較離散時會高於MAE。另外即使頻率分佈趨於集中，但是有極端值產生時，RMSE還是會大幅增加。\n",
    "<img src='images\\section-3\\rmse_mae_compare_2.jpg' style='width:700px;'>\n",
    "\n",
    "### 結論\n",
    "RMSE具有更多懲罰大誤差值的好處，因此在某些情況下可能更合適，例如，當我們希望誤差的幅度與頻率散布盡可能的小時我們會使用RMSE，但如果誤差的幅度大小在我們看來並不在意(不管誤差10或是誤差100都是一樣差)那麼MAE更合適。從解釋性的角度來看，MAE顯然更讓人容易理解。 RMSE不僅僅描述平均誤差，而且還有其他更難以梳理的含義。另一方面，RMSE相對於MAE的一個明顯優勢是RMSE避免使用絕對值，這在許多數學計算中是不可取的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More to come.....\n",
    "評估指標多種多樣，未來將補充更多重要的指標，例如:\n",
    "<li>precision\n",
    "<li>recall\n",
    "<li>f1-score\n",
    "<li>AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
