{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估指標與其用途\n",
    "\n",
    "在機器學習模型做出預測之後，用以衡量預測優劣的指標被稱為<b>評估指標</b>。機器學習分類任務的評估指標有<b>分類精度</b>和迴歸問題的<b>均方根誤差</b>..等等，評估指標可以提供明確客觀的依據，我們得以衡量機器學習流程的優劣，以下是幾個常見的情境:\n",
    "<li>以同樣資料來源但不同的縮放方法產生的資料，訓練同一個機器學習模型，使用評估指標能衡量用於此機器學習模型最好的一種縮放方法\n",
    "<li>以同樣資料、訓練多個機器學習模型，使用評估指標能衡量在使用此資料來源，使用哪一個機器學習模型的表現最佳\n",
    "<li>以同樣資料、訓練一種機器學習模型，但使用多組不同的參數，使用評估指標能衡量哪一組機器學習的參數最佳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標\n",
    "\n",
    "此筆記本中，將以Python實現四個標準預測\n",
    "<li>如何實現分類準確性。\n",
    "<li>如何實現和解釋混淆矩陣。\n",
    "<li>如何實現回歸的平均絕對誤差。\n",
    "<li>如何實現回歸的均方根誤差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一.分類(classification)評估指標\n",
    "此部分探討用於機器學習<b>分類</b>的評估指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以下兩變數actual_labels與predicted_labels將在分類評估指標的區饋被重複使用\n",
    "#變數actual_labels代表一資料集的真實標籤，predicted_labels代表機器學習模型預測的標籤\n",
    "\n",
    "#實際的標籤\n",
    "actual_labels =    [0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "#機器學習預測的標籤\n",
    "predicted_labels = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.分類準確性-Classification Accuracy\n",
    "最直觀的機器學習分類任務的評估指標，是計算其所有預測當中成功預測的百分比。分類準確性的結果是0-1之間的數字，0代表完全沒有成功的預測；1代表預測全部成功。分類準確性需要有正確的label以及機器學習預測的label來做評估。以下為公式:\n",
    "\n",
    "\\begin{align}\n",
    "accuracy = \\frac{correct prediction}{total prediction}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類準確性-python實作\n",
    "def accuracy_metric(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    分類準確性，計算所有預測中被正確預測的比例\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    一個介於0-1之間的數字，代表被正確預測的標籤的比例  \n",
    "    \"\"\"\n",
    "    correct = 0    \n",
    "    for i in range(len(actual_labels)):\n",
    "        if predicted_labels[i] == actual_labels[i]:\n",
    "            correct += 1\n",
    "    return correct / len(actual_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#計算準確性\n",
    "accuracy_metric(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上例分類準確性圖解\n",
    "<img src='https://ithelp.ithome.com.tw/upload/images/20181214/20111826cJCYEsNxBv.jpg' style='width:500px;float:left;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分類準確性之缺點\n",
    "分類準確性是很直觀的評估指標，我們得以知道預測命中的百分比。但是當遇到一些情形，分類準確性會失去其意義或表現得近乎假象。假設我們使用的機器學習模型是建立在二元分類的任務上(預測<b>是</b>或<b>否</b>)，但表現極差，對所有的分類預測都只預測為0。但是當遇到這樣的資料集；有高達90%的資料label為0，僅有10%為1，即使我們的機器學習模型只會預測全部標籤皆為0，但我們的分類準確性還是高達90%的準確率，讓我們誤以為機器學習模型的表現沒有問題。也因此當遇到分佈不平衡的資料集時(某一些類別多於其他類別)，時常分類準確性會誤導我們對機器學習模型表現的認知。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 混淆矩陣-Confushion matrix\n",
    "以下舉例以數值為0或1的二元分類為例。下圖表示分類預測任務中四種不同的結果劃分，分別是TP、TN、FP、FN。\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/512/1*-BkpqhN-5fPicMifDQ0SwA.png' style='width:500px;'><br/>\n",
    "<li>TP是true positive的縮寫，意思是被正確預測的正面(1)實例\n",
    "<li>FP是false positive的縮寫，是被錯誤預測為正面(1)實例的反面(0)實例\n",
    "<li>TN是true negative的縮寫，意思是被正確預測的反面(0)實例\n",
    "<li>FN是false negative，代表被錯誤預測為反面(0)實例的正面(1)實例<br/>\n",
    "<p>\n",
    "正因為分類的結果可以用TP、TN、FP、FN來劃分，因此光靠分類準確性使我們喪失了許多訊息，也對模型表現的認知有所偏誤。接下來探討機器學習分類任務中常用的衡量指標，也就是被稱為混淆矩陣的分類評估指標。混淆矩陣的概念是用來計算某類別被錯誤預測為其他類的次數。混淆矩陣是二維矩陣，且寬等於高。<br/>\n",
    "</p>\n",
    "    \n",
    ">配合下圖理解，一個簡單的理解方式是將混淆矩陣看成一個table，每一行(row)，代表一個實際類別，而該行的每一個欄位(column)該實際類別被預測為某類別的次數。\n",
    "<img src='https://ithelp.ithome.com.tw/upload/images/20181214/20111826gp06UqHJov.jpg' style='width:500px;'><br/>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confushion_matrix(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    混淆矩陣，計算所有被正確預測以及被錯誤預測為其他類別的次數總計\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    unique:一個所有類別的列表\n",
    "    matrix:一個混淆矩陣  \n",
    "    \"\"\"\n",
    "    \n",
    "    unique = set(actual_labels)#所有類別的列表\n",
    "    \n",
    "    matrix = [list() for x in range(len(unique))] \n",
    "    for i in range(len(unique)):\n",
    "        matrix[i] = [0 for j in range(len(unique))]\n",
    "        \n",
    "    lookup = {}\n",
    "    \n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "        \n",
    "    for i in range(len(actual_labels)):\n",
    "        x = lookup[actual_labels[i]]\n",
    "        y = lookup[predicted_labels[i]]\n",
    "        matrix[x][y] += 1\n",
    "        \n",
    "    return unique, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A)0 1\n",
      "(P)---\n",
      "0| 9 0\n",
      "1| 2 1\n"
     ]
    }
   ],
   "source": [
    "#視覺化混淆矩陣\n",
    "def print_confusion_matrix(unique, matrix):\n",
    "    print('(A)' + ' '.join(str(x) for x in unique))\n",
    "    print('(P)---')\n",
    "    for i, x in enumerate(unique):\n",
    "        print(\"%s| %s\" % (x, ' '.join(str(x) for x in matrix[i])))\n",
    "        \n",
    "lookup, matrix = confushion_matrix(actual_labels, predicted_labels)\n",
    "print_confusion_matrix(lookup, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.精密度-precision\n",
    "混淆矩陣為您提供了大量信息，但有時我們傾向更更簡潔且有直接敘述性的指標，我們可以使用稱為分類器的精密度(precision)作為指標。<br/>\n",
    "公式:\n",
    "\\begin{align}\n",
    "precision = \\frac{TP}{TP + FP}\n",
    "\\end{align}\n",
    "\n",
    "公式的含意是所有被分類為正面實例中實際被正確分類的比例。也就是被預測為1的資料當中，真正是1的的比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_metric(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    precision，公式的含意是所有被分類為正面實例中實際被正確分類的比例\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    precision:介於0-之間的數字，越高表現越好\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    tp_plus_fp = 0\n",
    "    \n",
    "    for i in range(len(actual_labels)):\n",
    "        if predicted_labels[i] == 1:\n",
    "            if actual_labels[i] == 1:\n",
    "                tp += 1\n",
    "            tp_plus_fp += 1\n",
    "    \n",
    "    return tp / tp_plus_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#計算精密度指標\n",
    "precision_metric(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.召回率-recall\n",
    "精密度指標通常與被稱為召回率的指標一起使用，召回率指標的公式如下:\n",
    "\n",
    "公式:\n",
    "\\begin{align}\n",
    "recall = \\frac{TP}{TP + FN}\n",
    "\\end{align}\n",
    "\n",
    "精密度指標代表著被預測為正面的實例當中正確的比例，但是在精密度指標我們只知道被預測為正面實例的正確率，卻少了實際為正面實例卻沒有被預測出來的觀點。召回率指標彌補了這個盲區，代表實際為正面實例當中有多少實例被正確預測、或說被模型認出來了。<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_metric(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    recall，代表正面實例當中有多少實例被正確預測的比例\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    recall:介於0-之間的數字，越高表現越好\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    tp_plus_fn = 0\n",
    "    \n",
    "    for i in range(len(actual_labels)):\n",
    "        if predicted_labels[i] == 1 and actual_labels[i] == 1:\n",
    "            tp += 1\n",
    "            tp_plus_fn += 1\n",
    "        elif predicted_labels[i] == 0 and actual_labels[i] == 1:\n",
    "            tp_plus_fn += 1\n",
    "\n",
    "        \n",
    "    return tp / tp_plus_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#召回率指標\n",
    "recall_metric(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.F1-score\n",
    "F1-score綜合考慮精密度指標與召回率指標，因此F1-score只有在兩者表現良好的情形下分數才會高。F1-score公式如下:\n",
    "\n",
    "公式:\n",
    "\\begin{align}\n",
    "f1 = 2\\times\\frac{precision \\times recall}{precision + recall}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    f1-score，綜合考慮𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛和𝑟𝑒𝑐𝑎𝑙𝑙的指標分數\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    f1-score:介於0-之間的數字，越高表現越好\n",
    "    \"\"\"\n",
    "    precision = precision_metric(actual_labels, predicted_labels)\n",
    "    recall = recall_metric(actual_labels, predicted_labels)\n",
    "    \n",
    "    f1 = 2*(precision*recall) / (precision + recall)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#計算f1-score\n",
    "f1_score(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精密度和召回率的權衡\n",
    "F1-score傾向於精密度和召回率相近的預測結果。這並非總是符合我們的需求：在某些情況下，你最關心的是精密度，在其他情況下你卻只在乎召回率。例如，做為自駕車的行人檢測與避障系統，因為牽涉到生命安全，所以對行人辨識的精密度和召回率都必須很講究，這時我們會使用f1-score作為指標。如果我們訓練分類器來檢測影片的分級(18+?)來過濾不適合兒童收看的影片，我們可能在意召回率高於精密度，因為召回率高代表正面例子被辨識出的比例高，而我們不在意是否有些非18+影片被錯認為18+的情形(寧可錯殺100也不願意放過任何一支不適合兒童觀看的影片)。不幸的是，除非精密度和召回率兩者本身都很高，否則精密度和召回率無法同時兼顧：提高精確度可以減少召回率反之亦然。這稱為精密度和召回率的權衡。<br/>\n",
    "<br/><br/>\n",
    "以下這張圖片解釋了二元分類下，精密度和召回率的權衡的概念，左邊的機率分布是為機器學習預測為反面的實例，右邊則為正面的實例，兩機率分佈有所重疊，是為被錯誤預測的實例(FN、FP)。\n",
    "<img src='https://ithelp.ithome.com.tw/upload/images/20181215/2011182664ox4SC5Tv.jpg' style='width:500px;'><br>\n",
    "通常對於分類的標準是，機器學習估計實例為正面類別的機率大於0.5的話我們就將其分類為正面類別。如果我們想高正面類別的精密度，那麼只要提高對機器學習估計機率的門檻就可以順利過濾掉FP，也就是反面實例被預測為正面實例的情形。但是提高了門檻以後FN的比例，也就是被認為是反面的正面實例。下圖，正面實例的預測精密度已經是100%，但是召回率卻大幅下降，因為正面實例有很大比例並未被正確預測出來。\n",
    "<img src='https://ithelp.ithome.com.tw/upload/images/20181215/20111826tOJqGwtwfp.jpg' style='width:500px;'><br>\n",
    "反之，如果我們降低了機器學習估計機率的門檻，則被誤認為正面實例的反面實例數量就會增加，造成正面實例預測的精密度下降，但是召回率提升。\n",
    "<img src='https://ithelp.ithome.com.tw/upload/images/20181215/20111826PBeKdsBYVW.jpg' style='width:500px;'><br>\n",
    "\n",
    "視下圖，找到一個界定正反面實例的機率門檻，使得精密度和召回率達到平衡，也最小化FP與FN的比例就是精密度和召回率的權衡的精神所在。對於精密度和召回率的權衡此筆記本僅探討至此，在後面章節進入機器學習演算法的章節再作補充。\n",
    "<img src='https://machinelearningblogcom.files.wordpress.com/2018/04/bildschirmfoto-2018-04-03-um-11-31-16.png?w=1400' style='width:1000px;'><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二.迴歸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "predicted = [0.11, 0.19, 0.29, 0.41, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 平均絕對誤差-Mean Absolute Error (MAE)\n",
    "平均絕對誤差測量一組預測中的誤差的平均幅度，而不考慮它們的正負。是測試樣本中預測和實際觀察之間絕對差異的平均值。公式如下:\n",
    "\\begin{align}\n",
    "MAE = \\frac{1}{n}\\times\\frac{\\sum_{i=1}^n|y_i - \\hat{y_i}|}{n - 1}\n",
    "\\end{align}\n",
    "另外如果MAE未採用絕對值（未消除誤差的符號），則平均誤差變為平均偏差誤差（MBE），並且通常用於測量平均模型偏差。 MBE可以傳達有用的信息，但應該謹慎解釋，因為正面和負面的錯誤都會被取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_metric(actual_values, predicted_values):\n",
    "    abs_error = 0\n",
    "    for i in range(len(actual_values)):\n",
    "        abs_error += abs(actual_values[i] - predicted_values[i])\n",
    "    return abs_error / len(actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007999999999999993"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mae_metric(actual, predicted)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.均方根誤差-Root-Mean-Square Error (RMSE)\n",
    "RMSE測量誤差的平均幅度。 它是預測和實際觀察之間平均差異平均值的平方根。公式如下:\n",
    "\\begin{align}\n",
    "RMSE = \\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}{\\Big(y_i - \\hat{y_i}\\Big)^2}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def rmse_metric(actual_values, predicted_values):\n",
    "    \"\"\"\n",
    "    均方根誤差，計算預測和實際觀察之間平均差異平均值的平方根\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    rmse:均方根誤差\n",
    "    \"\"\"\n",
    "    diff_sum = 0\n",
    "    for i in range(len(actual_values)):\n",
    "        diff_sum += (actual_values[i] - predicted_values[i])**2\n",
    "        \n",
    "    return sqrt(diff_sum / len(actual_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00894427190999915"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_metric(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE 與 RMSE之比較\n",
    "相似之處：MAE和RMSE都變量為單位表示平均模型預測誤差。 兩個度量都可以在0到∞的範圍內，並且正負無關緊要。 它們是負面導向的分數，這意味著較低的值更好。\n",
    "\n",
    "差異：取平均誤差的平方根對RMSE有一些有趣的影響。 由於誤差在平均之前是平方的，因此RMSE對大誤差給出相對較高的權重。 這意味著當特別不希望出現大錯誤時RMSE更有用。 下面的Case1-3顯示了MAE穩定且RMSE增加的示例，因為與誤差幅度的頻率分佈和方差的幅度差異。\n",
    "\n",
    "RMSE不一定隨著誤差的變化而增加，RMSE隨方差的誤差幅度和頻率分佈而增加。\n",
    "為了演示，請考慮下表中的案例4和案例5。 案例4具有相同數量的0和5的測試錯誤，案例5具有相同數量的3和4的測試錯誤。案例4中的錯誤差異更大但案例4和案例5的RMSE相同。也就是說當方差的頻率分佈較為集中時，RMSE的數值近於MAE，但是隨著頻率分佈較離散時會高於MAE。另外即使頻率分佈趨於集中，但是有極端值產生時，RMSE還是會大幅增加。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://ithelp.ithome.com.tw/upload/images/20181214/20111826istVtav0RA.jpg' style='width:1000px;float:left;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://ithelp.ithome.com.tw/upload/images/20181214/20111826tQ1ShERAlP.jpg' style='width:1000px;float:left;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE 與 RMSE之比較:結論\n",
    "RMSE具有更多懲罰大誤差值的好處，因此在某些情況下可能更合適，例如，當我們希望誤差的幅度與頻率散布盡可能的小時我們會使用RMSE，但如果誤差的幅度大小在我們看來並不在意(不管誤差10或是誤差100都是一樣差)那麼MAE更合適。從解釋性的角度來看，MAE顯然更讓人容易理解。 RMSE不僅僅描述平均誤差，而且還有其他更難以梳理的含義。另一方面，RMSE相對於MAE的一個明顯優勢是RMSE避免使用絕對值，這在許多數學計算中是不可取的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三.補充\n",
    "補充其他應用實作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. sklearn實作評估指標\n",
    "以下示範所有內容中以PYTHON實作的METRICS，以sklearn實作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "[[9 0]\n",
      " [2 1]]\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分類準確性-sklearn實作\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(actual_labels, predicted_labels))\n",
    "\n",
    "\n",
    "# 混淆矩陣-sklearn實作\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(actual_labels, predicted_labels))\n",
    "\n",
    "\n",
    "# 精準度-sklearn實作\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(precision_score(actual_labels, predicted_labels))\n",
    "\n",
    "\n",
    "# 召回率-sklearn實作\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(actual_labels, predicted_labels)\n",
    "\n",
    "\n",
    "# rmse-numpy實作\n",
    "import numpy as np\n",
    "\n",
    "def rmse_metric(actual_values, predicted_values):\n",
    "    \"\"\"\n",
    "    均方根誤差，計算預測和實際觀察之間平均差異平均值的平方根\n",
    "    \n",
    "    args:\n",
    "    actual_labels(list):正確的標籤(label) ,也被稱為 groung truth.\n",
    "    predicted_labels(list):機器學習模型所預測的標籤(label)\n",
    "    \n",
    "    return:\n",
    "    rmse:均方根誤差\n",
    "    \"\"\"\n",
    "    mse = np.mean((np.array(actual_values) - np.array(predicted_values))**2)\n",
    "        \n",
    "    return np.sqrt(mse)\n",
    "\n",
    "rmse_metric(actual, predicted)\n",
    "\n",
    "\n",
    "\n",
    "# f1-score-sklearn實作\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(actual_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.混淆矩陣的視覺化\n",
    "混淆矩陣視覺化相較於觀看數字來得直觀許多，以下演示用機器學習模型做分類預測，並用熱度圖作為混淆矩陣視覺化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 1 2 2 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#讀取鳶尾花資料集\n",
    "iris_data = load_iris()\n",
    "iris_length = iris_data['data']\n",
    "iris_labels = iris_data['target']\n",
    "#切割成訓練集以及測試集\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris_length, iris_labels, test_size=0.5)\n",
    "\n",
    "#訓練資料一覽\n",
    "(train_x[:10])\n",
    "#標籤資料一覽\n",
    "print(train_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "y_pred = clf.predict(test_x)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(confusion_matrix(test_y, y_pred), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More to come.....\n",
    "評估指標多種多樣，未來將補充更多重要的指標，例如:\n",
    "<li>f1-score\n",
    "<li>AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
