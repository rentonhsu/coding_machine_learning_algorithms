{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section-4 基線模型\n",
    "在預測建模問題上建立基線性能非常重要。 基線為我們稍後模型的評估提供了一個比較點。在此篇文章中，將探討如何在Python中從頭開始實現基線機器學習算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基線模型是什麼?\n",
    "有許多機器學習算法可供選擇，事實上數以百計。我們必須知道給定算法的預測是否良好，但我們將如何建立標準？ 答案是使用基線模型。基線預測算法提供了一組預測，可以像對問題的任何預測一樣進行評估，例如分類準確度或RMSE。 在評估問題的所有其他機器學習算法時，這些算法的分數提供了所需的比較點。 一旦建立，您可以評論給定算法與基線模型相比有多好，提供給定方法實際有多好的背景。 兩種最常用的基線算法是：\n",
    "<li>隨機預測算法\n",
    "<li>零規則預測算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 隨機預測法\n",
    "隨機預測算法預測在訓練數據中的隨機結果，說的直白一點等同於模擬模型亂猜，如此一來我們便能驗證自己選定的模型相對於亂猜的結果好了多少。以下演算法假設輸入的資料為table類型的格式，包含x(input)與y(output)的資料，y在每一筆紀錄的位置在最後一個欄位。而程式運作方式是先從train set中列舉出所有y的值，在對test set做預測時隨機從y值的窮舉當中隨機挑選作為預測。以下以分類任務的情境作為示範:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_prediction(train, test):\n",
    "    \"\"\"\n",
    "    Random predictions for test set.\n",
    "    \n",
    "    parameters:\n",
    "    train:The training data including X and y in the form of a table, y should be the last column. \n",
    "    test:The test set need to be prdicted.\n",
    "    \n",
    "    return:\n",
    "    Predicitons for test set.\n",
    "    \"\"\"\n",
    "    ys = [row[-1] for row in train]\n",
    "    unique_y = list(set(ys))\n",
    "    predictions = list()\n",
    "    \n",
    "    for _ in test:\n",
    "        random_pred = unique_y[random.randrange(len(unique_y))]\n",
    "        predictions.append(random_pred)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = [[1, 2, 3, 4, 1], \n",
    "         [1, 2, 3, 4, 2],\n",
    "         [1, 2, 3, 4, 1], \n",
    "         [1, 2, 3, 4, 1], \n",
    "         [1, 2, 3, 4, 2]]\n",
    "\n",
    "test = [[1, 2, 3, 4], \n",
    "        [1, 2, 3, 4], \n",
    "        [1, 2, 3, 4], \n",
    "        [1, 2, 3, 4], \n",
    "        [1, 2, 3, 4]]\n",
    "\n",
    "#模擬隨機預測\n",
    "random_prediction(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 零規則預測\n",
    "零規則預測是比隨機算法更好的基線模型。 它使用有關給定問題的更多信息來創建一個規則以進行預測。 此規則根據問題類型而不同。以分類任務為例子，常見的一個零規則預測作法是訂定一個規則，讓模型預測時的每一筆預測都使用訓練數據集中最常見的類值(眾數)來做為輸出。 這意味著，如果訓練數據集具有90個0級實例和10個1級實例，則它將預測0並實現90/100或90％的基線精度，用此規則當作基線模型我們就得以用來審視自己訓練出的機器學習模型而不被誤導(用零規則模型就達到了90%的準確率，我們選定的模型如果表現沒有比這個好則表示我們選定的模型並沒有什麼優勢)，比隨機預測算法要好得多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以分類任務的情境作為示範(以眾數作為預測規則)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_zero_rules(train, test):\n",
    "    ys = [row[-1] for row in train]\n",
    "    mode = max(set(ys), key=ys.count)\n",
    "    return [mode for _ in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = [[1, 2, 3, 4, 1], \n",
    "         [1, 2, 3, 4, 2],\n",
    "         [1, 2, 3, 4, 1], \n",
    "         [1, 2, 3, 4, 1], \n",
    "         [1, 2, 3, 4, 2]]\n",
    "\n",
    "test = [[1, 2, 3, 4], \n",
    "        [1, 2, 3, 4], \n",
    "        [1, 2, 3, 4], \n",
    "        [1, 2, 3, 4], \n",
    "        [1, 2, 3, 4]]\n",
    "\n",
    "#模擬每筆預測都是眾數\n",
    "mode_zero_rules(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以迴歸任務的情境作為示範(以y的算術平均數作為預測規則)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_zero_rules(train, test):\n",
    "    ys = [row[-1] for row in train]\n",
    "    mean = sum(ys) / len(train)\n",
    "    return [mean for _ in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4, 1.4, 1.4, 1.4, 1.4]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = [[1, 2, 3, 4, 1], \n",
    "         [1, 2, 3, 4, 2],\n",
    "         [1, 2, 3, 4, 1], \n",
    "         [1, 2, 3, 4, 1], \n",
    "         [1, 2, 3, 4, 2]]\n",
    "\n",
    "test = [[1, 2, 3, 4], \n",
    "        [1, 2, 3, 4], \n",
    "        [1, 2, 3, 4], \n",
    "        [1, 2, 3, 4], \n",
    "        [1, 2, 3, 4]]\n",
    "\n",
    "#模擬每筆預測都是眾數\n",
    "mean_zero_rules(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結語\n",
    "此篇探討了一些常見的基線模型，以下是一些擴展，例如中位數、時間序列中的移動平均值...等等。時常在實務當中我們可以藉由基線模型評估自己的模型準確度的程度，例如我個人時常透過基線模型發現自己的迴歸模型表現甚至低於某些零規則模型，如此有助於我們進一步探討並且制定優化模型的策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
