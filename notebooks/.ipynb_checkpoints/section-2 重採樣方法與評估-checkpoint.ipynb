{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重採樣方法\n",
    "\n",
    "機器學習建模的目標是創建能夠對新資料進行良好預測的模型；新資料的定義是在創造機器學習模型時還沒有被模型所\"學習\"的資料。換句話說就是在訓練資料以外的資料。因此我們必須使用統計方法來估計模型在預測新資料上的表現。\n",
    "\n",
    "### 什麼是重採樣方法\n",
    "\n",
    "重採樣方法的目標是充分利用訓練資料，估計機器學習模型在預測訓練資料以外的新資料的表現。重採樣方法可幫助機器學習的模型、特徵選擇。\n",
    "以下是兩種常見的重採樣方法:\n",
    "<li>train test split\n",
    "<li>k-fold Cross-Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.train test split\n",
    "\n",
    "train test split是最廣泛使用的重採樣方法，分成訓練、測試兩部分：\n",
    "<li>訓練資料集\n",
    "<li>測試資料集\n",
    "機器學習算法使用訓練數據集來訓練模型。並用測試資料於評估模型的性能。上述的兩種資料集是從現有資料中隨機抽樣，這是為了確保模型的訓練和評估是客觀的。常用的訓練、測試資料的比例為7:3、6:4、5:5。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <img src='./images/section_2/train_test.png' width=500> -->\n",
    "<img src='images/section_2/train_test.png' style='width:1000px;float:left;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_size=0.6):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets.\n",
    "    \n",
    "    parameters:\n",
    "    data(pandas.DataFrame):The input dataframe. \n",
    "    train_size(float):The ratio of training data.\n",
    "    \n",
    "    return:\n",
    "    train_data(pandas.DataFrame), test_data(pandas.DataFrame):train and test sets.\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    number_of_rows_for_train_data = len(data) * train_size\n",
    "    data_clone = list(data)\n",
    "    \n",
    "    while len(train_data) < number_of_rows_for_train_data:\n",
    "        random_index = randrange(len(data_clone))\n",
    "        train_data.append(data_clone.pop(random_index))\n",
    "        \n",
    "    test_data = data_clone\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3], [2], [7], [1], [8], [9]]\n",
      "[[4], [5], [6], [10]]\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "train, test = train_test_split(dataset)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sci-kit learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3], [9], [4], [5], [7], [6]]\n",
      "[[1], [10], [2], [8]]\n"
     ]
    }
   ],
   "source": [
    "#機器學習框架sklearn已有train_test_split的函式API可以使用\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "train, test = train_test_split(dataset, test_size=0.4)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.k-fold Cross-Validation Split\n",
    "\n",
    "使用train test split的重採樣方法來估算模型對於新資料的預測估計通常是有許多的noise。k-fold Cross-Validation Split（交叉驗證）提供更準確的估計。通過首先將資料分成k組，每組資料稱為折疊(fold)，因此名稱為k-fold交叉驗證。它的原理是用k-1組資料訓練機器學習模型並用剩下的一組資料作為測試集進行評估。而此切分的過程將進行k次，以確保每一個折疊都有被用於新資料的驗證上。\n",
    "\n",
    "為k選擇一個值，對於較小的數據集，k=3常用數字，對於較大的數據集則使用k=10。驗證折疊尺寸(k)是否具有代表性的快速方法是計算統計敘述，例如平均值和標準差，並從整個數據集的相同統計數據中查看值的差異，取預測精度最高的折疊尺寸。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <img src='./images/section_2/k-fold.png' width=500> -->\n",
    "\n",
    "<img src='images/section_2/k-fold.png' style='width:1000px;float:left;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_Cross_Validation_Split(data, k_folds):\n",
    "    \"\"\"\n",
    "    Split data into k folds.\n",
    "    \n",
    "    parameters:\n",
    "    data(pandas.DataFrame):The input dataframe. \n",
    "    k_folds(int):The number of data group after split.\n",
    "    \n",
    "    return:\n",
    "    folds(list(list)):k_fold_Cross_Validation_Split.\n",
    "    \"\"\"\n",
    "    fold_size = int(len(data) / k_folds)\n",
    "    folds = []\n",
    "    data_clone = list(data)\n",
    "    \n",
    "    for _ in range(k_folds):\n",
    "        fold = []\n",
    "        while len(fold) < fold_size:\n",
    "            random_index = randrange(len(data_clone))\n",
    "            fold.append(data_clone.pop(random_index))\n",
    "\n",
    "        folds.append(fold)\n",
    "    \n",
    "    return folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83, 50, 66, 38, 98, 84, 92, 0, 58, 80], [18, 85, 91, 31, 68, 9, 81, 59, 97, 33], [90, 70, 89, 60, 76, 57, 2, 45, 46, 54], [79, 56, 27, 41, 62, 4, 95, 20, 72, 16], [63, 69, 17, 10, 74, 28, 6, 11, 13, 5], [65, 3, 40, 37, 43, 22, 34, 67, 51, 12], [21, 23, 35, 61, 24, 93, 39, 94, 44, 78], [49, 87, 88, 15, 7, 30, 47, 42, 53, 25], [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]] [64, 29, 1, 26, 73, 75, 32, 55, 71, 48]\n",
      "[[64, 29, 1, 26, 73, 75, 32, 55, 71, 48], [18, 85, 91, 31, 68, 9, 81, 59, 97, 33], [90, 70, 89, 60, 76, 57, 2, 45, 46, 54], [79, 56, 27, 41, 62, 4, 95, 20, 72, 16], [63, 69, 17, 10, 74, 28, 6, 11, 13, 5], [65, 3, 40, 37, 43, 22, 34, 67, 51, 12], [21, 23, 35, 61, 24, 93, 39, 94, 44, 78], [49, 87, 88, 15, 7, 30, 47, 42, 53, 25], [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]] [83, 50, 66, 38, 98, 84, 92, 0, 58, 80]\n",
      "[[64, 29, 1, 26, 73, 75, 32, 55, 71, 48], [83, 50, 66, 38, 98, 84, 92, 0, 58, 80], [90, 70, 89, 60, 76, 57, 2, 45, 46, 54], [79, 56, 27, 41, 62, 4, 95, 20, 72, 16], [63, 69, 17, 10, 74, 28, 6, 11, 13, 5], [65, 3, 40, 37, 43, 22, 34, 67, 51, 12], [21, 23, 35, 61, 24, 93, 39, 94, 44, 78], [49, 87, 88, 15, 7, 30, 47, 42, 53, 25], [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]] [18, 85, 91, 31, 68, 9, 81, 59, 97, 33]\n",
      "[[64, 29, 1, 26, 73, 75, 32, 55, 71, 48], [83, 50, 66, 38, 98, 84, 92, 0, 58, 80], [18, 85, 91, 31, 68, 9, 81, 59, 97, 33], [79, 56, 27, 41, 62, 4, 95, 20, 72, 16], [63, 69, 17, 10, 74, 28, 6, 11, 13, 5], [65, 3, 40, 37, 43, 22, 34, 67, 51, 12], [21, 23, 35, 61, 24, 93, 39, 94, 44, 78], [49, 87, 88, 15, 7, 30, 47, 42, 53, 25], [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]] [90, 70, 89, 60, 76, 57, 2, 45, 46, 54]\n",
      "[[64, 29, 1, 26, 73, 75, 32, 55, 71, 48], [83, 50, 66, 38, 98, 84, 92, 0, 58, 80], [18, 85, 91, 31, 68, 9, 81, 59, 97, 33], [90, 70, 89, 60, 76, 57, 2, 45, 46, 54], [63, 69, 17, 10, 74, 28, 6, 11, 13, 5], [65, 3, 40, 37, 43, 22, 34, 67, 51, 12], [21, 23, 35, 61, 24, 93, 39, 94, 44, 78], [49, 87, 88, 15, 7, 30, 47, 42, 53, 25], [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]] [79, 56, 27, 41, 62, 4, 95, 20, 72, 16]\n",
      "[[64, 29, 1, 26, 73, 75, 32, 55, 71, 48], [83, 50, 66, 38, 98, 84, 92, 0, 58, 80], [18, 85, 91, 31, 68, 9, 81, 59, 97, 33], [90, 70, 89, 60, 76, 57, 2, 45, 46, 54], [79, 56, 27, 41, 62, 4, 95, 20, 72, 16], [65, 3, 40, 37, 43, 22, 34, 67, 51, 12], [21, 23, 35, 61, 24, 93, 39, 94, 44, 78], [49, 87, 88, 15, 7, 30, 47, 42, 53, 25], [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]] [63, 69, 17, 10, 74, 28, 6, 11, 13, 5]\n",
      "[[64, 29, 1, 26, 73, 75, 32, 55, 71, 48], [83, 50, 66, 38, 98, 84, 92, 0, 58, 80], [18, 85, 91, 31, 68, 9, 81, 59, 97, 33], [90, 70, 89, 60, 76, 57, 2, 45, 46, 54], [79, 56, 27, 41, 62, 4, 95, 20, 72, 16], [63, 69, 17, 10, 74, 28, 6, 11, 13, 5], [21, 23, 35, 61, 24, 93, 39, 94, 44, 78], [49, 87, 88, 15, 7, 30, 47, 42, 53, 25], [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]] [65, 3, 40, 37, 43, 22, 34, 67, 51, 12]\n",
      "[[64, 29, 1, 26, 73, 75, 32, 55, 71, 48], [83, 50, 66, 38, 98, 84, 92, 0, 58, 80], [18, 85, 91, 31, 68, 9, 81, 59, 97, 33], [90, 70, 89, 60, 76, 57, 2, 45, 46, 54], [79, 56, 27, 41, 62, 4, 95, 20, 72, 16], [63, 69, 17, 10, 74, 28, 6, 11, 13, 5], [65, 3, 40, 37, 43, 22, 34, 67, 51, 12], [49, 87, 88, 15, 7, 30, 47, 42, 53, 25], [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]] [21, 23, 35, 61, 24, 93, 39, 94, 44, 78]\n",
      "[[64, 29, 1, 26, 73, 75, 32, 55, 71, 48], [83, 50, 66, 38, 98, 84, 92, 0, 58, 80], [18, 85, 91, 31, 68, 9, 81, 59, 97, 33], [90, 70, 89, 60, 76, 57, 2, 45, 46, 54], [79, 56, 27, 41, 62, 4, 95, 20, 72, 16], [63, 69, 17, 10, 74, 28, 6, 11, 13, 5], [65, 3, 40, 37, 43, 22, 34, 67, 51, 12], [21, 23, 35, 61, 24, 93, 39, 94, 44, 78], [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]] [49, 87, 88, 15, 7, 30, 47, 42, 53, 25]\n",
      "[[64, 29, 1, 26, 73, 75, 32, 55, 71, 48], [83, 50, 66, 38, 98, 84, 92, 0, 58, 80], [18, 85, 91, 31, 68, 9, 81, 59, 97, 33], [90, 70, 89, 60, 76, 57, 2, 45, 46, 54], [79, 56, 27, 41, 62, 4, 95, 20, 72, 16], [63, 69, 17, 10, 74, 28, 6, 11, 13, 5], [65, 3, 40, 37, 43, 22, 34, 67, 51, 12], [21, 23, 35, 61, 24, 93, 39, 94, 44, 78], [49, 87, 88, 15, 7, 30, 47, 42, 53, 25]] [52, 14, 82, 96, 86, 19, 99, 8, 36, 77]\n"
     ]
    }
   ],
   "source": [
    "dataset = k_fold_Cross_Validation_Split(range(0, 100), k_folds=10)\n",
    "\n",
    "for i, _ in enumerate(dataset):\n",
    "    k_folds_clone = list(dataset)\n",
    "    test_dataset = k_folds_clone.pop(i)\n",
    "    train_dataset = k_folds_clone\n",
    "    print(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sci-kit learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      " 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n",
      " 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81\n",
      " 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99] [0 1 2 3 4 5 6 7 8 9]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
      " 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n",
      " 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81\n",
      " 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99] [10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 30 31 32 33\n",
      " 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n",
      " 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81\n",
      " 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99] [20 21 22 23 24 25 26 27 28 29]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n",
      " 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81\n",
      " 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99] [30 31 32 33 34 35 36 37 38 39]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 50 51 52 53 54 55 56 57\n",
      " 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81\n",
      " 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99] [40 41 42 43 44 45 46 47 48 49]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81\n",
      " 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99] [50 51 52 53 54 55 56 57 58 59]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 70 71 72 73 74 75 76 77 78 79 80 81\n",
      " 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99] [60 61 62 63 64 65 66 67 68 69]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 80 81\n",
      " 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99] [70 71 72 73 74 75 76 77 78 79]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 90 91 92 93 94 95 96 97 98 99] [80 81 82 83 84 85 86 87 88 89]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] [90 91 92 93 94 95 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dataset = range(0, 100)\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for fold in kf.split(dataset):\n",
    "    train_dataset, test_dataset = fold\n",
    "    print(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重採樣方法的選擇\n",
    "\n",
    "用於估算機器學習算法在新資料上的性能的標準是k-fold Cross Validation Split。相較於train test split，k-fold Cross Validation Split可提供穩健的估計。而k-fold Cross Validation Split的缺點是運行起來可能非常耗時(因為需要進行k次的計算)。對一個大型資料集，這是一個問題。train test split重採樣方法是最廣泛使用的。這是因為它很容易理解和實現，而且可以快速估算算法性能。雖然train test split方法對新資料的模型性能估計較為不可靠，但如果採樣的對象一個非常大的資料集，問題就不那麼嚴重了。大數據集通常是數十萬或數百萬條記錄中的數據集，足夠大到將資料分成兩半還具有幾乎相同的統計特性。在這種情況下，可能幾乎不需要使用k-fold Cross Validation Split作為評估，train test split可能同樣可靠。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
